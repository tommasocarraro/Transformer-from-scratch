def tokenize_(sentence):
    """
    It tokenizes the given sentence and returns a list of tokens.

    :param sentence: sentence to be tokenized
    :return: the tokenized sentence
    """
    return sentence.strip().split()
